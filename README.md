<div align="center">
  <img width="351" height="85" alt="image" src="https://github.com/user-attachments/assets/497af966-9f89-4af8-b5aa-aa3b08a7ce2f" />

  # Interview Practice Partner

  An AI-powered voice-based interview practice platform that helps users prepare for job interviews through realistic mock interviews, real-time feedback, and adaptive scenarios across multiple roles.

  [![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

</div>

## ğŸ¥ Demo Video

**[Demo Video Link - To Be Added]**

*A 10-minute screen recording demonstration showcasing:*
- *The agent's ability to handle multiple user personas (Confused, Efficient, Chatty)*
- *Real-time voice interactions and responses*
- *Role-specific interview flows (Software Engineer, Sales Representative, Product Manager, etc.)*
- *Code editor integration for technical interviews*
- *AI-generated feedback and analysis*

---

## âœ¨ Features

- **ğŸ­ Multiple Role Support**: Practice for Software Engineer, Sales Representative, Product Manager, Retail Associate, and more
- **ğŸ—£ï¸ Voice-First Interface**: Complete hands-free experience with automatic speech detection and AI voice responses
- **ğŸ’» Interactive Code Editor**: Real-time code editing with syntax highlighting for technical interviews (Software Engineer role)
- **ğŸ¯ Role-Specific Flows**: Tailored interview questions and formats based on the selected role
- **ğŸ§  Adaptive AI**: Intelligently handles different user personas and communication styles
- **ğŸ“Š AI-Powered Feedback**: Comprehensive post-interview analysis with strengths, improvements, and actionable tips
- **â±ï¸ Smart Session Management**: Auto-inactivity detection, Focus Mode for silent coding, and timer tracking
- **ğŸ“± Fully Responsive**: Works seamlessly on desktop, tablet, and mobile devices
- **ğŸ¨ Modern UI/UX**: Clean, intuitive interface with real-time visual feedback

## ğŸ—ï¸ Architecture

### Tech Stack

**Frontend:**
- **Framework**: Next.js 16.0.3 with React 19.2.0 and Turbopack
- **Styling**: Tailwind CSS with custom design system
- **UI Components**: Framer Motion for animations, Lucide React for icons
- **Code Editor**: Monaco Editor (VS Code engine) for technical interviews
- **Voice**: Web Speech API (Browser-native SpeechRecognition and SpeechSynthesis)
- **Notifications**: Sonner for toast messages
- **Language**: TypeScript with strict type checking

**Backend:**
- **Framework**: FastAPI (Python)
- **AI Engine**: LangChain + Google Gemini Pro
- **Memory**: LangChain ConversationBufferMemory for session context
- **State Management**: In-memory session storage with UUID-based session IDs
- **API**: RESTful endpoints with CORS support

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Next.js App (page.tsx)                                â”‚ â”‚
â”‚  â”‚  - Session Management                                  â”‚ â”‚
â”‚  â”‚  - State Orchestration                                 â”‚ â”‚
â”‚  â”‚  - UI Rendering                                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                  â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  VoiceInput Component    â”‚  â”‚  Monaco Code Editor     â”‚  â”‚
â”‚  â”‚  - Speech Recognition    â”‚  â”‚  - Syntax Highlighting  â”‚  â”‚
â”‚  â”‚  - Silence Detection     â”‚  â”‚  - Language Support     â”‚  â”‚
â”‚  â”‚  - Auto Restart Logic    â”‚  â”‚  - Question Pasting     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Speech Synthesis (TTS)  â”‚  â”‚  Video Components       â”‚  â”‚
â”‚  â”‚  - AI Voice Response     â”‚  â”‚  - User/Interviewer     â”‚  â”‚
â”‚  â”‚  - Code Filtering        â”‚  â”‚  - Green Highlight      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ HTTP/REST API
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Backend                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  FastAPI Server (main.py)                              â”‚  â”‚
â”‚  â”‚  - /chat endpoint: Process user messages               â”‚  â”‚
â”‚  â”‚  - /feedback endpoint: Generate analysis               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â”‚                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Agent Core              â”‚  â”‚  Memory Module          â”‚   â”‚
â”‚  â”‚  - Interview Chain       â”‚  â”‚  - Session History      â”‚   â”‚
â”‚  â”‚  - Prompt Management     â”‚  â”‚  - Context Retention    â”‚   â”‚
â”‚  â”‚  - Response Generation   â”‚  â”‚  - In-Memory Store      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                 â”‚                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  System Prompts (prompts.py)                          â”‚   â”‚
â”‚  â”‚  - Role-specific interview flows                      â”‚   â”‚
â”‚  â”‚  - Coding question format instructions                â”‚   â”‚
â”‚  â”‚  - Feedback generation templates                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Google Gemini Pro API                     â”‚
â”‚  - Natural Language Understanding                            â”‚
â”‚  - Context-Aware Response Generation                         â”‚
â”‚  - Interview Question Creation                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

**1. Interview Orchestrator (Backend)**
- Manages conversation flow and state transitions
- Routes messages through LangChain pipeline
- Maintains session context via memory module
- Generates role-specific responses

**2. Voice Processing (Frontend)**
- **Speech Recognition**: Browser-native API with continuous listening mode
- **Silence Detection**: Multi-strategy approach (interim results, final results, watchdog timers)
- **Auto-Restart Logic**: Intelligent mic management to prevent loops
- **Echo Prevention**: Stops user mic when AI is speaking

**3. Memory System**
- Uses LangChain's `ConversationBufferMemory`
- Session-based storage with UUID identifiers
- Maintains full conversation history for context
- Powers the feedback generation with complete transcript

**4. Code Editor Integration**
- Detects `[CODING_QUESTION_START]...[CODING_QUESTION_END]` markers
- Automatically extracts and pastes code with problem description
- Multi-language support (Python, JavaScript, Java, C++, etc.)
- Syntax highlighting and intelligent formatting

**5. Feedback Engine**
- Analyzes complete interview transcript
- Provides structured feedback (Strengths, Areas for Improvement, Tips)
- Markdown-formatted output with proper styling
- Actionable recommendations for improvement

### Design Decisions

**1. Browser-Based Voice Processing**
- **Why**: Zero-latency interaction, no API costs, privacy-first approach
- **Trade-off**: Browser compatibility requirements, but 95%+ support
- **Benefit**: Instant feedback and natural conversation flow

**2. Voice-Only Interface**
- **Why**: Simulates real interview conditions, forces verbal communication
- **Decision**: Removed chat interface completely in favor of pure voice
- **Benefit**: More realistic practice, better communication skill development

**3. Marker-Based Code Injection**
- **Why**: Reliable code extraction from AI responses
- **Method**: AI wraps coding questions in explicit markers
- **Benefit**: Clean separation between problem description and code

**4. Stateless REST API**
- **Why**: Simplicity, scalability, easy to test and debug
- **Implementation**: Session state in memory, mapped by session_id
- **Trade-off**: Sessions lost on server restart (acceptable for MVP)

**5. Multi-Strategy Speech Detection**
- **Challenge**: Browser speech API can be unreliable
- **Solution**: Multiple fallback timers (silence detection, watchdog, max duration)
- **Result**: Robust speech detection that works in various conditions

**6. Role-Specific Prompts**
- **Why**: Different roles need completely different interview styles
- **Implementation**: Single prompt with conditional logic based on role
- **Benefit**: Maintainable, extensible, accurate to real interviews

**7. Responsive Mobile-First Design**
- **Why**: Users may practice on any device
- **Implementation**: Tailwind breakpoints, flexible layouts
- **Benefit**: Works on phones, tablets, laptops, and desktops

**8. Focus Mode for Coding**
- **Why**: Developers code silently during technical interviews
- **Solution**: Disables both 3-minute inactivity warnings AND proactive AI code check-ins during Focus Mode
- **Benefit**: Allows completely uninterrupted coding flow - the AI won't ask about your code until you exit Focus Mode
- **Note**: You can toggle Focus Mode on/off anytime during the interview

## ğŸš€ Setup Instructions

### Prerequisites

Ensure you have the following installed:
- **Node.js**: v18.0.0 or higher ([Download](https://nodejs.org/))
- **Python**: v3.9.0 or higher ([Download](https://www.python.org/))
- **Google Gemini API Key**: Get one from [Google AI Studio](https://makersuite.google.com/app/apikey)
- **Modern Web Browser**: Chrome, Edge, or Safari (for Web Speech API support)

### Step 1: Clone the Repository

```bash
git clone <repository-url>
cd Interview-Practice-Partner
```

### Step 2: Backend Setup

1. **Navigate to the backend directory:**
   ```bash
   cd backend
   ```

2. **Create and activate a virtual environment:**

   **Windows:**
   ```bash
   python -m venv venv
   venv\Scripts\activate
   ```

   **Mac/Linux:**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Install Python dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Create environment file:**

   Create a `.env` file in the `backend/` directory:
   ```env
   GOOGLE_API_KEY=your_gemini_api_key_here
   ```

   Replace `your_gemini_api_key_here` with your actual Google Gemini API key.

5. **Start the backend server:**
   ```bash
   python main.py
   ```

   The server will start on `http://localhost:8000`

   You should see:
   ```
   INFO:     Uvicorn running on http://0.0.0.0:8000
   INFO:     Application startup complete.
   ```

### Step 3: Frontend Setup

1. **Open a new terminal and navigate to the frontend directory:**
   ```bash
   cd frontend
   ```

2. **Install Node.js dependencies:**
   ```bash
   npm install
   ```

3. **Start the development server:**
   ```bash
   npm run dev
   ```

   The app will start on `http://localhost:3000`

   You should see:
   ```
   â–² Next.js 16.0.3
   - Local:        http://localhost:3000
   - Ready in X.Xs
   ```

4. **Open your browser:**

   Navigate to [http://localhost:3000](http://localhost:3000)

### Step 4: Grant Microphone Permissions

When you first start an interview, your browser will request microphone access. Click **Allow** to enable voice interaction.

---

## ğŸ¯ How to Use

### Starting an Interview

1. **Select a Role**: Choose from Software Engineer, Sales Representative, Product Manager, Retail Associate, or enter a custom role
2. **Set Timer** (Optional): Choose interview duration (15, 30, or 45 minutes)
3. **For Software Engineer**: Select your preferred programming language
4. **Click "Start Interview"**
5. **For Software Engineer Only**: Review the instructions dialog and click "Got it, let's begin!"

### During the Interview

**Voice Interaction:**
- Speak naturally when the status shows "Listening"
- Your video border turns green when you're speaking
- The AI's video highlights when it's responding
- The mic automatically manages itself - no buttons to press!

**Software Engineer Specific:**
- Coding questions appear automatically in the editor
- Use **Focus Mode** (top-right button) when you want to code without interruptions
  - **What it does**: Prevents AI from asking about your code AND disables inactivity warnings
  - **When to use**: When you want complete silence while implementing your solution
  - **Toggle anytime**: Turn it on when coding, off when ready to discuss
- The AI can see your code and will proactively ask questions (unless Focus Mode is on)
- Video toggles available for distraction-free coding

**General:**
- Timer counts down in the top-right corner
- Session auto-ends after 3 minutes of complete inactivity (unless in Focus Mode)
- Click **End Session** anytime to finish and view feedback

### Ending the Interview

1. Click the **End Session** button
2. The AI will generate a comprehensive analysis
3. Review your feedback covering:
   - âœ… **Strengths**: What you did well
   - ğŸ“ˆ **Areas for Improvement**: What to work on
   - ğŸ’¡ **Actionable Tips**: Specific recommendations
4. Click **Start New Session** to practice again

---

## ğŸ­ User Personas & Adaptive Behavior

The AI agent intelligently adapts to different communication styles:

### 1. **Confused User**
- **Behavior**: Uncertain about what to do, asks basic questions
- **Example**: "I don't know what to do" or "What happens now?"
- **AI Response**: Provides gentle guidance, explains the process, offers clear next steps

### 2. **Efficient User**
- **Behavior**: Direct, wants to get started immediately
- **Example**: "Interview me for Senior Java Developer" or "Let's start"
- **AI Response**: Jumps straight into the interview, minimal pleasantries, focused questions

### 3. **Chatty User**
- **Behavior**: Goes off-topic, talks about unrelated things
- **Example**: "The weather is nice today" or "I had coffee this morning"
- **AI Response**: Politely acknowledges but steers conversation back to interview focus

### 4. **Silent Coder** (Software Engineer)
- **Behavior**: Codes without speaking for extended periods
- **Example**: User types in editor for 2+ minutes without talking
- **AI Response**: Proactively asks specific questions about the code being written

### 5. **Anxious User**
- **Behavior**: Multiple false starts, frequent pauses
- **Example**: "Um... uh... I mean..."
- **AI Response**: Patient, gives time to think, doesn't rush

---

## ğŸ§ª Testing & Demonstration Scenarios

### Test Scenario 1: The Confused User â“

**Objective**: Test how the agent guides uncertain users

**Test Input:**
```
User: "Um... I'm not sure what this is"
```

**Expected AI Behavior:**
- Provides gentle, clear guidance
- Explains the interview process
- Asks what role they're interested in
- Offers to start when ready

**Actual Result:** âœ… PASS
- AI responds: "No problem! This is an AI-powered interview practice platform. I'll conduct a realistic mock interview with you for any role you'd like to practice. What position are you interested in interviewing for?"

**Key Success Metrics:**
- âœ… Non-judgmental tone
- âœ… Clear explanation provided
- âœ… Guides toward next step
- âœ… Waits for user to be ready

---

### Test Scenario 2: The Efficient User âš¡

**Objective**: Test direct, no-nonsense interaction

**Test Input:**
```
User: "Interview me for Senior Software Engineer. Python. Let's go."
```

**Expected AI Behavior:**
- Skips pleasantries
- Immediately starts interview
- No unnecessary questions
- Gets straight to coding challenge

**Actual Result:** âœ… PASS
- AI responds with brief acknowledgment and immediately presents coding question
- No "how are you" or small talk
- Respects user's time and efficiency

**Key Success Metrics:**
- âœ… Minimal response time
- âœ… No unnecessary dialogue
- âœ… Immediate value delivery
- âœ… Focused on content

---

### Test Scenario 3: The Chatty User ğŸ’¬

**Objective**: Test off-topic conversation handling

**Test Input:**
```
User: "The weather is really nice today! I had such a good breakfast. Do you like coffee?"
```

**Expected AI Behavior:**
- Politely acknowledges
- Redirects to interview context
- Maintains professional boundaries
- Doesn't engage in off-topic discussion

**Actual Result:** âœ… PASS
- AI responds: "I appreciate you sharing that! However, let's focus on helping you prepare for your interview. Shall we continue with the next question about your experience with [relevant topic]?"

**Key Success Metrics:**
- âœ… Polite but firm redirection
- âœ… Maintains interview context
- âœ… Doesn't ignore user completely
- âœ… Smoothly transitions back

---

### Test Scenario 4: Edge Case - Invalid/Gibberish Input ğŸ”€

**Objective**: Test handling of nonsensical or invalid inputs

**Test Input:**
```
User: "asdfkjh wqoeiru zxcvmn"
```

**Expected AI Behavior:**
- Gracefully handles unclear input
- Asks for clarification
- Doesn't crash or give error
- Maintains professional tone

**Actual Result:** âœ… PASS
- AI responds: "I didn't quite catch that. Could you please repeat or rephrase?"
- Continues listening without breaking flow

**Key Success Metrics:**
- âœ… No crashes or errors
- âœ… Polite clarification request
- âœ… Continues session normally
- âœ… User can recover easily

---

### Test Scenario 5: Edge Case - Beyond Capabilities ğŸš«

**Objective**: Test handling of requests outside agent's scope

**Test Input:**
```
User: "Write my resume for me" or "Can you help me with my math homework?"
```

**Expected AI Behavior:**
- Clearly states limitations
- Explains what it CAN do
- Offers alternative within scope
- Maintains helpful tone

**Actual Result:** âœ… PASS
- AI responds: "I'm specifically designed to help you practice for job interviews. I can't write your resume, but I can conduct mock interviews to help you articulate your experience better. Would you like to practice answering 'Tell me about yourself'?"

**Key Success Metrics:**
- âœ… Clear boundary setting
- âœ… Explains purpose/scope
- âœ… Offers relevant alternative
- âœ… Stays helpful and positive

---

### Test Scenario 6: Edge Case - Inappropriate Content ğŸ›‘

**Objective**: Test handling of offensive or inappropriate input

**Test Input:**
```
User: [Offensive language or inappropriate request]
```

**Expected AI Behavior:**
- Firmly but professionally declines
- Sets clear boundaries
- Doesn't engage with content
- Refocuses on interview purpose

**Actual Result:** âœ… PASS
- AI responds: "I'm here to help you with interview preparation in a professional manner. Let's keep our conversation focused on that. Are you ready to continue with the interview?"

**Key Success Metrics:**
- âœ… Firm boundary enforcement
- âœ… Professional response
- âœ… No engagement with inappropriate content
- âœ… Clear path forward

---

### Test Scenario 7: Silent Coder (Proactive Agent) ğŸ¤–

**Objective**: Test proactive behavior during coding silence

**Setup**: Software Engineer role, user codes silently for 2+ minutes

**Expected AI Behavior:**
- Detects silence during coding
- Analyzes current code
- Asks specific, relevant question
- Doesn't interrupt too frequently

**Actual Result:** âœ… PASS
- After 2 minutes of silent coding, AI proactively asks: "I see you're using a hash map there. Could you explain why you chose that data structure?"
- Question is specific to the code being written
- Timing is appropriate (not too soon, not too late)

**Key Success Metrics:**
- âœ… Detects coding activity
- âœ… Analyzes code context
- âœ… Asks relevant questions
- âœ… Appropriate timing

---

### Test Scenario 8: Multi-Turn Context Retention ğŸ§ 

**Objective**: Test memory and context awareness

**Test Flow:**
```
Turn 1 - User: "I worked at Google for 3 years"
Turn 2 - User: "I specialized in distributed systems"
Turn 3 - AI should reference both facts
```

**Expected AI Behavior:**
- Remembers previous statements
- References context naturally
- Builds on information
- Asks follow-up questions based on history

**Actual Result:** âœ… PASS
- AI's Turn 3 response: "Given your 3 years at Google working on distributed systems, can you tell me about a challenging scalability problem you solved?"
- Correctly combines both context pieces
- Natural reference integration

**Key Success Metrics:**
- âœ… Full conversation history retained
- âœ… Natural context integration
- âœ… Relevant follow-up questions
- âœ… No repetition of questions

---

## ğŸ“Š Testing Summary

| Scenario | Status | Conversational Quality | Adaptability | Intelligence |
|----------|--------|----------------------|--------------|--------------|
| Confused User | âœ… PASS | Excellent | High | High |
| Efficient User | âœ… PASS | Excellent | High | High |
| Chatty User | âœ… PASS | Excellent | High | High |
| Invalid Input | âœ… PASS | Good | Medium | Medium |
| Beyond Capabilities | âœ… PASS | Good | High | High |
| Inappropriate Content | âœ… PASS | Excellent | High | High |
| Silent Coder | âœ… PASS | Excellent | Very High | Very High |
| Context Retention | âœ… PASS | Excellent | High | Very High |

**Overall Test Success Rate: 100% (8/8 scenarios passed)**

### Key Strengths Demonstrated:
1. âœ… **Excellent Conversational Quality**: Natural, context-aware responses across all scenarios
2. âœ… **Strong Agentic Behavior**: Proactive, adaptive, with clear boundaries
3. âœ… **High Intelligence**: Contextual understanding, memory retention, relevant questioning
4. âœ… **Robust Edge Case Handling**: Graceful degradation, clear error handling

### Areas for Continuous Improvement:
- More varied conversational patterns to avoid predictability
- Even faster response times for efficient users
- Enhanced code analysis capabilities for deeper technical discussions

---

## ğŸ“‚ Project Structure

```
Interview-Practice-Partner/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ core.py              # Interview chain & feedback generation
â”‚   â”‚   â”œâ”€â”€ memory.py            # Session history management
â”‚   â”‚   â”œâ”€â”€ monitoring.py        # Logging utilities
â”‚   â”‚   â””â”€â”€ prompts.py           # System prompts & instructions
â”‚   â”œâ”€â”€ main.py                  # FastAPI server
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â””â”€â”€ .env                     # API keys (create this)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ layout.tsx           # Root layout
â”‚   â”‚   â”œâ”€â”€ page.tsx             # Main interview page
â”‚   â”‚   â””â”€â”€ globals.css          # Global styles
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ VoiceInput.tsx       # Speech recognition logic
â”‚   â”‚   â”œâ”€â”€ CodeEditor.tsx       # Monaco editor wrapper
â”‚   â”‚   â”œâ”€â”€ FeedbackPanel.tsx    # Analysis display
â”‚   â”‚   â”œâ”€â”€ InstructionsDialog.tsx  # Onboarding for Software Engineers
â”‚   â”‚   â”œâ”€â”€ UserVideo.tsx        # User video feed
â”‚   â”‚   â”œâ”€â”€ InterviewerVideo.tsx # AI avatar
â”‚   â”‚   â””â”€â”€ ModeToggle.tsx       # Dark/light theme
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts               # API client functions
â”‚   â”‚   â””â”€â”€ utils.ts             # Utility functions
â”‚   â”œâ”€â”€ package.json             # Node dependencies
â”‚   â”œâ”€â”€ next.config.ts           # Next.js configuration
â”‚   â””â”€â”€ tailwind.config.ts       # Tailwind CSS config
â””â”€â”€ README.md                    # This file
```

---

## ğŸ”§ Configuration

### Backend Configuration

Edit `backend/agent/core.py` to change AI model:

```python
llm = ChatGoogleGenerativeAI(
    model="gemini-pro",  # Change model here
    temperature=0.7,      # Adjust creativity (0.0 - 1.0)
    google_api_key=os.getenv("GOOGLE_API_KEY")
)
```

**Available Models:**
- `gemini-pro` - Stable, widely available (60 RPM free tier)
- `gemini-1.5-flash-latest` - Faster responses
- `gemini-2.0-flash` - Latest version

### Frontend Configuration

Edit `frontend/lib/api.ts` to change backend URL:

```typescript
const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';
```

---

## ğŸ› Troubleshooting

### Backend Issues

**Problem**: `ModuleNotFoundError: No module named 'langchain'`
- **Solution**: Activate virtual environment and run `pip install -r requirements.txt`

**Problem**: `404 models/gemini-pro is not found`
- **Solution**: Check your API key is correct in `.env` and has Gemini API enabled

**Problem**: `Rate limit exceeded`
- **Solution**: Wait a few minutes (free tier limits) or upgrade your API plan

### Frontend Issues

**Problem**: "Failed to send message" error
- **Solution**: Ensure backend is running on `http://localhost:8000`

**Problem**: Microphone not working
- **Solution**: Check browser permissions, use HTTPS or localhost, ensure modern browser

**Problem**: Green highlight not showing when speaking
- **Solution**: Speak louder/clearer, check mic is not muted, restart browser

**Problem**: Code not pasting into editor
- **Solution**: Ensure backend is using the latest prompts, restart backend server

### Voice Recognition Issues

**Problem**: Mic keeps starting and stopping
- **Solution**: Reduce background noise, speak clearly, check console for errors

**Problem**: Speech not detected or inconsistent recognition
- **Solution**:
  * **Speak louder and more clearly** into the microphone
  * **Check microphone is not muted** in system settings (Windows: Sound Settings > Input)
  * **Reduce background noise** (close windows, turn off fans, move to quieter area)
  * **Position correctly**: Move closer to mic or adjust mic sensitivity
  * **Test your microphone**: Open Voice Recorder (Windows) or QuickTime (Mac) to verify mic works
  * **Use Chrome or Edge**: These have the best Web Speech API support
  * **Restart browser**: Close and reopen to grant fresh microphone permissions
  * **Check console logs**: Open Developer Tools (F12) and look for "ğŸ¤ MIC IS LISTENING" when speaking
  * **Check mic levels**: In Windows, open Sound Settings > Input and speak - the blue bar should move
  * **Try a different mic**: If using external mic, try laptop built-in mic or vice versa

---

## ğŸš¦ System Requirements

### Minimum Requirements
- **OS**: Windows 10+, macOS 10.15+, or Linux
- **RAM**: 4GB
- **Browser**: Chrome 80+, Edge 80+, Safari 14.1+
- **Internet**: Stable connection for API calls

### Recommended Requirements
- **RAM**: 8GB or more
- **Browser**: Latest version of Chrome or Edge
- **Microphone**: Good quality mic for best speech recognition
- **Internet**: Broadband connection (10+ Mbps)

---

## ğŸ“ Notes

- Sessions are stored in memory and will be lost when the backend server restarts
- The free tier of Gemini API has rate limits (60 requests per minute)
- Web Speech API works best in quiet environments with clear speech
- For production deployment, consider adding database persistence for sessions
- Code editor supports 50+ programming languages via Monaco Editor

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit issues or pull requests.

---

## ğŸ“„ License

This project is licensed under the MIT License - see below for details.

```
MIT License

Copyright (c) 2025 Interview Practice Partner

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

<div align="center">
  Made with â¤ï¸ by Hanish Rishen
</div>

---

## ğŸ“„ License

This project is open source and available under the MIT License.
